{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "",
  "signature": "sha256:680a6e3a7ce94b3a1f812ad97ddd0a345da6968fcdbd84675f63544c44823124"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Topic modeling Bigartm v0.8.0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from pandas.tools.plotting import table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import artm\n",
      "import os\n",
      "os.environ['ARTM_SHARED_LIBRARY']='/opt/bigartm/lib/libartm.so'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new batches\n",
      "# enter your /home/USER/directory/ and the collection name which is between docword/vocab and .txt\n",
      "\n",
      "#batch_vectorizer = artm.BatchVectorizer(data_path='/home/USER/directory/', data_format='bow_uci', collection_name='yourcollectionname', target_folder='yourcollectionname_batches', batch_size=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load batches\n",
      "# enter your /home/USER/directory/\n",
      "batch_vectorizer = artm.BatchVectorizer(data_path=\"/home/USER/directory/\", data_format='batches')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T = 8 # just a random number of topics, later try again with another number. Similarly with the number of num_tokens below\n",
      "model_artm = artm.ARTM(num_topics=T,\n",
      "                       num_document_passes=120, reuse_theta=True, cache_theta=True, seed=-1, scores=[artm.TopTokensScore(name='top_tokens_score')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = artm.Dictionary()\n",
      "dictionary.gather(data_path='/home/USER/directory/', vocab_file_path='vocab.yourcollectionname.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
      "                                           dictionary=dictionary))\n",
      "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
      "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
      "model_artm.scores.add(artm.TopTokensScore(name=\"top_words\", num_tokens=20))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.initialize(dictionary=dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Offline-algorithm: many passes through the collection, one pass through the document (optional), updating $\\Phi$ at the end of each pass. Use it if you have a small collection. Online-algorithm: one pass through the collection (optional), many passes through the document, update $\\Phi$ one times per a given number of batches. Used for a large collection, and a collection with a rapidly changing theme."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of iterations can be monitored according to the graph of perplexia.\n",
      "ARTM is not a genie in a bottle! The model is difficult to train and the results need a solid dose of interpretation. This is especially true in the context of tweets that construct rather noisy documents. In an unsupervised context, estimating the performance of the model requires either manual assessment or some quality metric. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(model_artm.score_tracker[\"PerplexityScore\"].value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic_name in model_artm.topic_names:\n",
      "    print topic_name + ': ',\n",
      "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
      "    for word in tokens[topic_name]:    \n",
      "        print word,\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sparseness of matrices:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
      "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This regularizer suppresses words that have a high frequency in the entire collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-100, dictionary=dictionary))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic_name in model_artm.topic_names:\n",
      "    print topic_name + ': ',\n",
      "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
      "    for word in tokens[topic_name]:    \n",
      "        print word,\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
      "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try to change the regularization coefficient:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_artm.regularizers['SparsePhi'].tau = -5*1e4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic_name in model_artm.topic_names:\n",
      "    print topic_name + ': ',\n",
      "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
      "    for word in tokens[topic_name]:    \n",
      "        print word,\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
      "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save and load the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#model_artm.save(\"*\")\n",
      "# * enter your collection name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_artm.load(\"my_model\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if you want to look at matrices:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phi = model_artm.get_phi()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The matrix of probabilities of topics in documents:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta = model_artm.get_theta()\n",
      "theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you need to get theta matrix for new batches but do not need to train the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "'''\n",
      "batch_vectorizer_test = artm.BatchVectorizer(data_path='/home/USER/directory', data_format='bow_uci', collection_name='yourcollectionname', target_folder='yourcollectionname_batches', batch_size=100)\n",
      "theta_test = model_artm.transform(batch_vectorizer_test)\n",
      "theta_test\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "matrix theta \u2014 a matrix of themes distribution on documents, \n",
      "matrix phi \u2014 a matrix of word distribution on topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "ax = plt.subplot(111, frame_on=False) # no visible frame\n",
      "ax.xaxis.set_visible(False)  # hide the x axis\n",
      "ax.yaxis.set_visible(False)  # hide the y axis\n",
      "\n",
      "table(ax, theta)  # where theta is dataframe\n",
      "\n",
      "plt.savefig('mytable.png')\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model_artm.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.regularizers['decorrelator_phi_regularizer'].tau = 1e+5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic_name in model_artm.topic_names:\n",
      "    print topic_name + ': ',\n",
      "    tokens = model_artm.score_tracker[\"top_words\"].last_tokens\n",
      "    for word in tokens[topic_name]:    \n",
      "        print word,\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model_artm.score_tracker[\"SparsityPhiScore\"].last_value\n",
      "print model_artm.score_tracker[\"SparsityThetaScore\"].last_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}